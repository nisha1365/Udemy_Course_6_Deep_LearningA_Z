{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 9: ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 34: Plan of Attack\n",
    "- <img src=\"../images/Conv_1.png\" alt=\"Drawing\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 35: What are Convolutional Nueral Networks?\n",
    "- <img src=\"../images/Conv_2.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- <img src=\"../images/Conv_3.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- The model is similar to the ANN because it requires an input which will output the highest prob. (kind of obvious)\n",
    "- <img src=\"../images/Conv_4.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- Noticed that with a black and white image, you are only measuring the pixel through the a 2D array. However for color images, we use a 3D array.\n",
    "    - <img src=\"../images/Conv_5.png\" alt=\"Drawing\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 36: Step 1 - Convolutional Operation\n",
    "- <img src=\"../images/Conv_6.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "- Feature Detector does not need to be a 3 by 3 matrix. Other use 7 by 7 or 5 by 5. \n",
    "- The 3 by 3 is a conventional!\n",
    "- Process\n",
    "    - Feature detector can be also be called filter or kernel\n",
    "    - The feature detector hovers overs the respective # of pixels in the input image. In our example, we have a 3 by 3 meaning we hover over the first 3 by 3 (top right corner)\n",
    "    - We then multiply (element-wise) meaning the first pixel (1 by 1) gets multiplied by the 1 by 1 position pixel in the feature detector\n",
    "    - We then add all of these # and present the result in the feature map.\n",
    "    - Noticed how in the position 1 by 1 in the feature map is 0 bc we all the #'s are 0 (1 and 0 are being multiplied)\n",
    "- <img src=\"../images/Conv_7.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- The image above eventually becomes the image below!!\n",
    "- <img src=\"../images/Conv_8.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- **Feature map can also be a convult feature or activation map**\n",
    "- Using the feature detector, we were able to reduce the size of the image. The Convolutional is to make the image smaller bc it will be easier to process it. (faster)\n",
    "- Are we losing info. when we apply the feature detector?\n",
    "    - Yes, but the main point is to find the feature that are pivotal for the outcome! Meaning that looking at our specifc feature dectors is looking for some features (labeled as 1), then we can find other features that map those as they are!\n",
    "    - Very similar to how we see. We do not look at every feature, we look at features in a whole!\n",
    "- **The Convolutional Neural Network** works similar to ANN as we have to create a lot of filter (feature maps)\n",
    "- Each feature map will be trained to find the appropriate filter (or feature map) to get ONLY the desired features that the specfic feature detector has be trained\n",
    "    - <img src=\"../images/Conv_9.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "- The goal of a Convolutional Neural Network is to find features in the image (using the feature detector) and put them in the feature map. Keeping the spacial relationship (recall the blur, emboss, etc changes in the image is still the image just with a slight change)\n",
    "\n",
    "\n",
    "- **FEATURE DETECTOR SHOULD BE USED INSTEAD OF FILTER SINCE WE ARE LOOKING AT PART IN THE IMAGE THAT ARE SIMILAR TO THE ONE IN THE FEATURE DETECTOR**\n",
    "\n",
    "- **RECALL THAT WE USE TO FIND FIND FEATURES USING THE FEATURES MAP AND KEEP THE SPATIAL RELATIONSHIP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 37: Step 1(b) - ReLU Layer\n",
    "- <img src=\"../images/Conv_10.png\" alt=\"Drawing\" style=\"width: 600px;\">\n",
    "- The following images are an example of an image changes based on the feature map. \n",
    "- <img src=\"../images/Conv_11.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- <img src=\"../600px/Conv_12.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- <img src=\"../images/Conv_13.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "- ** THE RELU** makes the second image to the third bc the black are negatives. Thus, in the function, anything that is negative becomes gray. The is done to take away the linearity in the image!\n",
    "- You take away the progression (from white to black) when you apply the ReLU! \n",
    "- Breaking up linearity means that we are not going to measure every change of the pixel as proportional. Hence, when we apply this ReLU, we get to take away the black backgrounds. Such change does not necessarily matter for our prediction and may mean nothing if it is a part of a background. \n",
    "\n",
    "- If we think about it the example shows that we do not go from white to black, but only from white to gray. This is not a proprtional change since we skip the black portion!\n",
    "- That why we use RELU function, anything below 0 becomes black, (which is how we label the darker pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 38: Step 2 - Pooling\n",
    "- One of the difficulties with image recogition is that the images are not all the same. Some images might have the desired thing you're looking for facing in a different way or in a differernt part of the photo\n",
    "- Spacian invariance: the convolutional should not care if the feature is tilted or closer, etc. The feature that the neural has learned\n",
    "- <img src=\"../images/Conv_14.png\" alt=\"Drawing\" style=\"width: 500px;\"> \n",
    "- In the image above we noticed that the pooled feature map works similar to the feature map. You do one full step (not partial like in the feature map), and get the map # or pixel of that quadrant. This will work similar if we use the mean, median, etc pooling\n",
    "- <img src=\"../images/Conv_15.png\" alt=\"Drawing\" style=\"width: 500px;\"> \n",
    "- Map pooling is we used because when we look at the quadrant, we are getting the same value regardless of where in the quadrant the higher number is. Things might work differently if we were to use an upside down image, etc but we will see\n",
    "- <img src=\"../images/Conv_16.png\" alt=\"Drawing\" style=\"width: 500px;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 39: Step 3 - Flattening\n",
    "- You flattened the entire matrix into one vector bcause you will later need to use it in  format of a vector for further processing!\n",
    "- <img src=\"../images/Conv_17.png\" alt=\"Drawing\", style=\"width: 500px;\"> \n",
    "- <img src=\"../images/Conv_18.png\" alt=\"Drawing\", style=\"width: 500px;\"> \n",
    "- <img src=\"../images/Conv_19.png\" alt=\"Drawing\", style=\"width: 500px;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 40: Step 4 - Full Connections\n",
    "- The process looks quite similar to the ANN. The difference i s that we need to focus on the feature map, and max pooling which will in turn make the entire process a bit longer!\n",
    "- In the image below, we see that we must focus on the way on each specific possible outcome (dog or cat in the example below)\n",
    "- <img src=\"../images/Conv_20.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- <img src=\"../images/Conv_21.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- In the hidden layers, we run from less recongizable feature to recongizable features!\n",
    "- <img src=\"../images/Conv_22.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- In the image above, we learned that the three neuron serve a great importance to the dog classification\n",
    "- The cat has a different arangement of the nuerons\n",
    "    - <img src=\"../images/Conv_23.png\" alt=\"Drawing\", style=\"width: 500px;\"> \n",
    "- We can see the image below how the nuerons are affected for each animal differently\n",
    "- <img src=\"../images/Conv_24.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- We can think of the neuron as features (if the model begins to find that certain neurons create a higher accuracy) it will adapt those neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 41: Summary\n",
    "- You start with an input image\n",
    "- You apply a feature map to reduce the size of the image (it's using the map detector)\n",
    "    - These feature maps were not exlicitly explained how htey are made\n",
    "- Convultional layer: The layer that is filtreed!\n",
    "- When we get the convolutional layer, we then apply the ReLU since we do not want the image to remain linear (every change in pixel should not have a proportional change to the outcome)\n",
    "- We then apply a pooling layer since we get to reduce the size and spatial indifference (image might be in a diff. size, or position)\n",
    "- We then flattened out the vector and put the vector into a ANN (each vector are many possibilities tht could happen)\n",
    "- Not only are the weight are trained in an ANN model but also the features detectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 42: Softmax & Cross-Entropy\n",
    "- One of the things we realize, we understand that the outcomes add upto 1. In the beginning, it does not, since the answer is a regular number.\n",
    "- However, we perform the softmax function which will output a number between 0 and 1, and add upto 1.\n",
    "- <img src=\"../images/Conv_25.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "- The function squashes the result\n",
    "- The SOFTMAX comes hand in hand with the Cross-Entropy function\n",
    "    - <img src=\"../images/Conv_26.png\" alt=\"Drawing\" style=\"width: 300px;\"> \n",
    "    - **rememember:** You need to assign the value of p with the actual prob (either 1 or 0) and the q is defined as the actual prob from the softmax function\n",
    "    - This is used instead of the MSE\n",
    "    - Pretty much the cost function but for convolutional networks, we have to name is loss function\n",
    "    - We have to minimize the Cross-Entropy function\n",
    "    - <img src=\"../images/Conv_27.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "- Example\n",
    "    - <img src=\"../images/Conv_28.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "    - Network 1 performed better than Network 2\n",
    "    - **Type of Error**\n",
    "        - <img src=\"../images/Conv_29.png\" alt=\"Drawing\" style=\"width: 500px;\">\n",
    "        - Classification Error: How many right did you get (it does not pay attention to the prob). Thus, both neural networks performed the same. It is not a good measure since we cannot measure it relative to one another on the actual performance of the models!\n",
    "        - MSE: 0.25 (for Neural Network 1),  0.71 (for Neural Network 2)\n",
    "        - Cross-Entropy: 0.38 (for Neural Network 1),  1.06 (for Neural Network 2)\n",
    "    - But why use cross-entropy over MSE?\n",
    "        - For example, if we are using the MSE, when we compare two different cost function, they must be different from one another. If they are around the same, without many improvement, the model will not be able to distinguish btw both models. \n",
    "        - However the cross-entropy use the log function which magnifies small output!\n",
    "        - cross-entropy is better for classification\n",
    "        - The thing you will find out is that we update our weight with the softmax, the small changes are magnified unlike with the MSE since it just updates the previous beta with any changes\n",
    "- https://www.youtube.com/watch?v=mlaLLQofmR8\n",
    "- The e in the oftmax function is the exponent of what we are looking at"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
